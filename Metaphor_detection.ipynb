{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metaphor detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VedSengupta/word_abstractness_estimator/blob/master/Metaphor_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUJx0scSQy4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup\n",
        "!pip install -q wordcloud\n",
        "import wordcloud\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo1pSMEZd7VH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.parse.stanford import StanfordDependencyParser\n",
        "!pip install stanfordcorenlp\n",
        "!pip install parse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dct7Q7jjfmjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from parse import parse\n",
        "\n",
        "def dependency_parse(sentence):\n",
        "    \"\"\" Accepts a sentence and returns its dependency parse as a list-of-lists\n",
        "    Also returns the list of nouns in the sentence\n",
        "    \"\"\"\n",
        "\n",
        "    # sentence =input(\"Enter a sentence: \")\n",
        "\n",
        "    parser_folder = \"parser\"    # Change if parser is in some other directory\n",
        "    parse_output = parse(sentence, parser_folder)\n",
        "\n",
        "    # List of nouns\n",
        "    const_parse = parse_output[0]\n",
        "    print(const_parse)\n",
        "    regex_pattern = r\"\\(NN (\\w+)\\)\"\n",
        "    NN_list = re.findall(r\"\\(NN (\\w+)\\)\", const_parse)\n",
        "    NNS_list = re.findall(r\"\\(NNS (\\w+)\\)\", const_parse)\n",
        "\n",
        "    noun_list = sorted(NN_list + NNS_list)\n",
        "\n",
        "    # Dependency parse\n",
        "    dep_parse = parse_output[1].split(\"\\n\")\n",
        "\n",
        "    print (\"---\")\n",
        "    dependency_parse=[]\n",
        "    for i in dep_parse:\n",
        "        if len(i.strip()) > 0 and i.strip()[0] != \"(\":\n",
        "            line=i.strip()\n",
        "            dependency_parse.append(filter(lambda x:x.isalpha(),re.findall(r\"[\\w']+\", line)))\n",
        "\n",
        "    return dependency_parse, noun_list\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sentence =input(\"Enter a sentence: \")\n",
        "\n",
        "    print(dependency_parse(sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoXdrEYTSQKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FngzXpW2TJs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from setuptools import setup\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMgMVMKCeGey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUBY1nURSaDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "39347267-abcd-463d-aeb8-0b7f7077c664"
      },
      "source": [
        "def detect_metaphor(sentence):\n",
        "   dep_parse_output, noun_list =dependency_parse((sentence.lower())\n",
        "   nsubj_pairs = [ns_parse[1:] for ns_parse in filter(lambda dp: dp[0] == \"nsubj\" and dp[1] in noun_list and dp[2] in noun_list, dep_parse_output)]\n",
        "   for pair in nsubj_pairs:\n",
        "       print (\"\\nInvestigating metaphor for pair {0}\".format(pair))\n",
        "\n",
        "       syn_pair = []\n",
        "       for word in pair:\n",
        "\n",
        "             synsets = wn.synsets(word)\n",
        "             print (\"What sense of '{0}' would you like to use?\".format(word))\n",
        "             for i, synset in enumerate(synsets):\n",
        "                 print (\"{0}: {1}\".format(i, synset.definition))\n",
        "             chosen_id = int(raw_input(\"Enter number corresponding to sense: \"))\n",
        " \n",
        "             syn_pair.append(synsets[chosen_id])\n",
        "       \n",
        "       similarity_measure = similarity(syn_pair[0], syn_pair[1])\n",
        "       \n",
        "       if similarity_measure is None or similarity_measure >= 0.1:\n",
        "            print (\"{0} does NOT constitute a Noun-Noun metaphor, similarity {1}\".format(pair, similarity_measure))\n",
        "       else:\n",
        "            print (\"{0} constitutes a Noun-Noun metaphor, similarity {1}\".format(pair, similarity_measure))\n",
        "\n",
        "   if len(nsubj_pairs) == 0:\n",
        "        print (\"No Noun-Noun pairs detected. Thus the sentence is not a Noun-Noun metaphor\")\n",
        "      \n",
        "      \n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-491c6115e084>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    nsubj_pairs = [ns_parse[1:] for ns_parse in filter(lambda dp: dp[0] == \"nsubj\" and dp[1] in noun_list and dp[2] in noun_list, dep_parse_output)]\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASSOy-moXV7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz_cPYfOdMVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def similarity(synset1, synset2):\n",
        "    \"\"\" Accepts 2 synsets and returns the similarity\n",
        "    \"\"\"\n",
        "\n",
        "    return synset1.path_similarity(synset2)\n",
        "if __name__ == \"__main__\":\n",
        "    sentence =input(\"Enter a sentence: \")\n",
        "\n",
        "    detect_metaphor(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZageil4XtZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYn0Rn_QSxmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}